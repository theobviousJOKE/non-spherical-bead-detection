{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7076d0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c73e222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_yaml(data: dict, path: str):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    with open(path, 'w') as file:\n",
    "        yaml.dump(data, file, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c795283e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOTrainer:\n",
    "    def __init__(self, model_path: str):\n",
    "        self.model = YOLO(model_path)\n",
    "\n",
    "    def train(self, data_yaml: str, epochs: int, imgsz: int, batch: int):\n",
    "        return self.model.train(\n",
    "            data=data_yaml,\n",
    "            epochs=epochs,\n",
    "            imgsz=imgsz,\n",
    "            batch=batch\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf36477",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoFrameLoader(torch.utils.data.Dataset):\n",
    "    def __init__(self, video_path):\n",
    "        self.cap = cv2.VideoCapture(video_path)\n",
    "        self.length = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        self.current = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        self.cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ret, frame = self.cap.read()\n",
    "        if not ret:\n",
    "            raise IndexError(\"Frame index out of range or unreadable frame.\")\n",
    "        return frame\n",
    "\n",
    "    def release(self):\n",
    "        self.cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db733d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOInference:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def detect(self, frame):\n",
    "        results = self.model.predict(frame)\n",
    "        bounding_boxes = []\n",
    "        for result in results:\n",
    "            for box in result.boxes.xyxy:\n",
    "                bounding_boxes.append([int(x.item()) for x in box])\n",
    "        return bounding_boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca888a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AngleAnalyzer:\n",
    "    def __init__(self, regions=3):\n",
    "        self.regions = regions  # e.g., 3 or 10\n",
    "\n",
    "    def divide_regions(self, y, h, anchor):\n",
    "        region_height = (h - anchor) // self.regions\n",
    "        for i in range(self.regions):\n",
    "            if y < anchor + (i + 1) * region_height:\n",
    "                return i\n",
    "        return self.regions - 1\n",
    "\n",
    "    def extract_angles(self, frame, bounding_boxes, anchor, height):\n",
    "        region_angles = {f'region_{i+1}': [] for i in range(self.regions)}\n",
    "        for box in bounding_boxes:\n",
    "            x1, y1, x2, y2 = box\n",
    "            roi = frame[y1:y2, x1:x2]\n",
    "            try:\n",
    "                gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "                blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "                binary = cv2.adaptiveThreshold(blurred, 255,\n",
    "                                               cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                               cv2.THRESH_BINARY_INV, 11, 2)\n",
    "                contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                if contours:\n",
    "                    contour = max(contours, key=cv2.contourArea).reshape(-1, 2)\n",
    "                    if contour.shape[0] >= 2:\n",
    "                        pca = PCA(n_components=2)\n",
    "                        pca.fit(contour)\n",
    "                        angle = np.arctan2(pca.components_[0, 1], pca.components_[0, 0]) * 180 / np.pi\n",
    "                        if angle < 0:\n",
    "                            angle = 180 - abs(angle)\n",
    "                        center_y = (y1 + y2) // 2\n",
    "                        region_idx = self.divide_regions(center_y, height, anchor)\n",
    "                        region_key = f'region_{region_idx+1}'\n",
    "                        region_angles[region_key].append(angle)\n",
    "            except Exception:\n",
    "                continue\n",
    "        return region_angles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9910f623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(\n",
    "    video_path, out_path, yolo_model, region_count=3, frame_step=1, draw=True\n",
    "):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    out = cv2.VideoWriter(out_path, fourcc, fps, (width, height))\n",
    "\n",
    "    inference = YOLOInference(yolo_model)\n",
    "    analyzer = AngleAnalyzer(region_count)\n",
    "\n",
    "    anchor = None\n",
    "    frames_angles = {}\n",
    "    frame_idx = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if frame_idx % frame_step == 0:\n",
    "            boxes = inference.detect(frame)\n",
    "            if not boxes:\n",
    "                out.write(frame)\n",
    "                frame_idx += 1\n",
    "                continue\n",
    "            if anchor is None:\n",
    "                anchor = min([box[1] for box in boxes])\n",
    "            region_angles = analyzer.extract_angles(frame, boxes, anchor, height)\n",
    "            frames_angles[frame_idx] = region_angles\n",
    "            if draw:\n",
    "                for box in boxes:\n",
    "                    x1, y1, x2, y2 = box\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                # Draw region lines\n",
    "                region_height = (height - anchor) // region_count\n",
    "                for i in range(1, region_count):\n",
    "                    y_line = anchor + i * region_height\n",
    "                    cv2.line(frame, (0, y_line), (width, y_line), (255, 0, 0), 2)\n",
    "            out.write(frame)\n",
    "        frame_idx += 1\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    return frames_angles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dfcf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_region_kde(frames_angles, regions, frame_mod=100):\n",
    "    for frame, region_dict in frames_angles.items():\n",
    "        if frame % frame_mod == 0 or frame == 0:\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            for i in range(regions):\n",
    "                region_key = f'region_{i+1}'\n",
    "                abs_angles = [abs(a) for a in region_dict.get(region_key, [])]\n",
    "                if abs_angles:\n",
    "                    sns.kdeplot(abs_angles, label=f'Region {i+1} KDE')\n",
    "            plt.title(f\"KDE of Angles per Region, Frame {frame}\")\n",
    "            plt.xlabel(\"Angle (degrees)\")\n",
    "            plt.ylabel(\"Density\")\n",
    "            plt.xlim(0, 180)\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43b1a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Write YAML data settings\n",
    "write_yaml(\n",
    "    {\n",
    "        'train': 'C:/Users/Predator/Desktop/gpu_env_folder/AA_PProject/dataset_red&trans/images/train',\n",
    "        'val': 'C:/Users/Predator/Desktop/gpu_env_folder/AA_PProject/dataset_red&trans/images/val',\n",
    "        'nc': 1,\n",
    "        'names': {'0': 'non-spherical'}\n",
    "    },\n",
    "    'C:/Users/Predator/Desktop/gpu_env_folder/AA_PProject/dataset_red&trans/data3.yaml'\n",
    ")\n",
    "\n",
    "# 2. Train YOLOv8 model (if needed)\n",
    "trainer = YOLOTrainer('yolov8s.pt')\n",
    "trainer.train(\n",
    "    data_yaml='C:/Users/Predator/Desktop/gpu_env_folder/AA_PProject/dataset_red&trans/data3.yaml',\n",
    "    epochs=110,\n",
    "    imgsz=640,\n",
    "    batch=32\n",
    ")\n",
    "\n",
    "# 3. Process a video and analyze angle regions\n",
    "frames_angles = process_video(\n",
    "    video_path=r'C:\\Users\\Predator\\Desktop\\gpu_env_folder\\AA_PProject\\videos\\fr24_start30sec.mp4',\n",
    "    out_path=r'C:\\Users\\Predator\\Desktop\\gpu_env_folder\\AA_PProject\\output\\fr24_start30sec_3div.mp4',\n",
    "    yolo_model=trainer.model,\n",
    "    region_count=3,\n",
    "    frame_step=1,\n",
    "    draw=True\n",
    ")\n",
    "\n",
    "# 4. KDE Plot (change \"region_count\" for different splits)\n",
    "plot_region_kde(frames_angles, regions=3)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
